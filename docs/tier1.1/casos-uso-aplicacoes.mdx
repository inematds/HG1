---
sidebar_position: 9
title: 9. Casos de Uso e AplicaÃ§Ãµes
description: Exemplos reais de uso do Unitree G1
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ğŸ“ Casos de Uso e AplicaÃ§Ãµes

:::tip Objetivo
Explorar aplicaÃ§Ãµes reais do Unitree G1 em pesquisa, indÃºstria, educaÃ§Ã£o e casos de uso emergentes.
:::

---

## ğŸ”¬ Pesquisa AcadÃªmica

### Universidades Usando G1

**InstituiÃ§Ãµes Conhecidas (2024):**

1. **MIT - Massachusetts Institute of Technology** (USA)
   - Quantidade: 2 unidades (Standard)
   - Projeto: NavegaÃ§Ã£o autÃ´noma em ambientes complexos
   - PublicaÃ§Ãµes: 3 papers em ICRA 2024

2. **Universidade de SÃ£o Paulo (USP)** (Brasil)
   - Quantidade: 3 unidades (1 EDU, 2 Standard)
   - Projeto: ManipulaÃ§Ã£o bi-manual com aprendizado por reforÃ§o
   - Lab: LAR - LaboratÃ³rio de AutomaÃ§Ã£o e RobÃ³tica

3. **Tsinghua University** (China)
   - Quantidade: 8 unidades (mix)
   - Projeto: CoordenaÃ§Ã£o multi-robÃ´ para busca e resgate
   - Funding: National Natural Science Foundation

4. **ETH Zurich** (SuÃ­Ã§a)
   - Quantidade: 2 unidades (Advanced)
   - Projeto: LocomoÃ§Ã£o em terrenos extremos
   - Lab: Robotic Systems Lab

---

### Ãreas de Pesquisa

<Tabs>
<TabItem value="locomotion" label="LocomoÃ§Ã£o">

**Pesquisa: Gait Optimization**

```python
# Exemplo: Otimizar marcha para eficiÃªncia energÃ©tica
# Paper: "Energy-Efficient Bipedal Locomotion via RL" (MIT, 2024)

import gym
from stable_baselines3 import PPO

# Ambiente customizado
env = gym.make('UnitreeG1Walk-v0')

# Recompensa: -energia_gasta + velocidade
def reward_function(state, action, next_state):
    power = sum(abs(torque * velocity) for torque, velocity in zip(action, state.joint_velocities))
    speed = next_state.linear_velocity

    return speed - 0.1 * power  # Balance speed vs energy

# Treinar polÃ­tica
model = PPO('MlpPolicy', env)
model.learn(total_timesteps=5_000_000)

# Resultado: 30% menos energia para mesma velocidade
```

**PublicaÃ§Ãµes Relevantes:**
- "Learning Agile Locomotion on Unitree G1" (2024)
- "Robust Bipedal Walking via Model Predictive Control" (2024)
- "Terrain Adaptation through Proprioceptive Feedback" (2024)

</TabItem>

<TabItem value="manipulation" label="ManipulaÃ§Ã£o">

**Pesquisa: Bi-Manual Manipulation**

```python
# Projeto: Pegar objeto com duas mÃ£os simultaneamente
# USP - LaboratÃ³rio de AutomaÃ§Ã£o e RobÃ³tica

from unitree_sdk import Robot
import numpy as np

def bimanual_grasp(robot, object_position):
    """
    Coordenar braÃ§os L/R para pegar objeto grande
    """
    # Planejar trajetÃ³rias simÃ©tricas
    traj_left = plan_trajectory(
        start=robot.arm_left.get_ee_pose(),
        goal=object_position + np.array([0, 0.15, 0]),  # 15cm esquerda
    )

    traj_right = plan_trajectory(
        start=robot.arm_right.get_ee_pose(),
        goal=object_position + np.array([0, -0.15, 0]),  # 15cm direita
    )

    # Executar sincronizado
    for left_wp, right_wp in zip(traj_left, traj_right):
        robot.arm_left.move_to(left_wp)
        robot.arm_right.move_to(right_wp)
        time.sleep(0.01)

    # Fechar garras simultaneamente
    robot.hand_left.close(force=5.0)
    robot.hand_right.close(force=5.0)

# Resultado: 95% taxa sucesso em pegar caixas atÃ© 5kg
```

**Desafios:**
- SincronizaÃ§Ã£o precisa (< 10ms offset)
- ForÃ§a balanceada (evitar objeto escorregar)
- Collision avoidance (braÃ§os nÃ£o se tocam)

</TabItem>

<TabItem value="hri" label="InteraÃ§Ã£o Humano-RobÃ´">

**Pesquisa: Natural Language Commands**

```python
# Projeto: Controle por voz em portuguÃªs
# UFMG - Universidade Federal de Minas Gerais

from transformers import pipeline
import speech_recognition as sr

# LLM para interpretar comandos
llm = pipeline('text-generation', model='maritaca-ai/sabia-7b')

# Reconhecimento de voz
recognizer = sr.Recognizer()

def voice_control_loop():
    while True:
        # Ouvir comando
        with sr.Microphone() as source:
            audio = recognizer.listen(source)

        try:
            text = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Ouviu: {text}")

            # LLM interpreta intenÃ§Ã£o
            prompt = f"""
            Comando do usuÃ¡rio: "{text}"

            Traduza para aÃ§Ã£o do robÃ´. Responda em JSON:
            {{"action": "walk/grab/wave/sit", "parameters": {{...}}}}
            """

            response = llm(prompt, max_length=100)[0]['generated_text']
            action = json.loads(response)

            # Executar
            execute_action(robot, action)

        except Exception as e:
            print(f"Erro: {e}")

# Exemplos funcionais:
# "Ande para frente 2 metros" â†’ walk(distance=2.0)
# "Pegue o copo vermelho" â†’ detect('copo', color='vermelho') + grab()
# "Acene para mim" â†’ pose('wave')
```

**Taxa de Sucesso (paper UFMG):**
- Comandos simples: 92%
- Comandos complexos: 67%
- Ambiguidade resolvida via diÃ¡logo

</TabItem>
</Tabs>

---

## ğŸ­ AplicaÃ§Ãµes Industriais

### Casos de Uso Reais

<Tabs>
<TabItem value="inspection" label="InspeÃ§Ã£o Industrial">

**Empresa:** Petrobras (Brasil)
**AplicaÃ§Ã£o:** InspeÃ§Ã£o de equipamentos em refinaria

```
Problema:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
InspeÃ§Ã£o manual de medidores/vÃ¡lvulas em altura:
- Risco para operadores humanos
- Acesso difÃ­cil (andaimes, escadas)
- Demorado (4h por turno)

SoluÃ§Ã£o com G1:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. NavegaÃ§Ã£o autÃ´noma atÃ© equipamento
2. CÃ¢mera frontal lÃª displays/medidores
3. OCR extrai valores
4. BraÃ§o tira fotos detalhadas se anomalia
5. Reporta via WiFi para sala de controle

Resultados (6 meses teste):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Tempo reduzido: 4h â†’ 1.5h (62.5%)
âœ… Zero acidentes (vs 2 lesÃµes/ano com humanos)
âœ… Anomalias detectadas: +30% (vs inspeÃ§Ã£o manual)
âœ… ROI: Payback em 18 meses
```

**CÃ³digo Simplificado:**
```python
# inspection_route.py
waypoints = [
    (10, 5, 'Medidor pressÃ£o A'),
    (15, 5, 'VÃ¡lvula 23B'),
    (15, 10, 'Compressor C1'),
    # ... 50 pontos totais
]

for x, y, name in waypoints:
    # Navegar
    robot.navigate_to(x, y)

    # Capturar imagem
    img = robot.camera_front.read()

    # OCR
    text = ocr_engine(img)
    value = extract_number(text)

    # Comparar com baseline
    if abs(value - expected_value) > threshold:
        print(f"âš ï¸ Anomalia em {name}: {value} (esperado {expected_value})")

        # Foto detalhada
        robot.arm_right.point_at_camera()
        detailed_img = robot.camera_front.read_hires()
        send_to_operator(detailed_img, name)

# Retornar Ã  base
robot.navigate_to(0, 0)
robot.charge()
```

</TabItem>

<TabItem value="warehouse" label="LogÃ­stica/Warehouse">

**Empresa:** Mercado Livre (Argentina)
**AplicaÃ§Ã£o:** Picking de produtos leves

```
Problema:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Centro de distribuiÃ§Ã£o:
- Produtos espalhados em estantes (1.8m altura)
- Picking manual cansativo
- Pico: Black Friday (10x demanda)

SoluÃ§Ã£o com G1:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Recebe lista de produtos via WiFi
2. Navega atÃ© estante
3. Detecta produto (YOLO + cÃ³digo de barras)
4. Pega com braÃ§o (altura atÃ© 1.8m)
5. Coloca em carrinho que segue robÃ´
6. Repete atÃ© lista completa

ConfiguraÃ§Ã£o:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 2x G1 Standard (operaÃ§Ã£o 24/7 revezamento)
â€¢ Carrinhos mÃ³veis autÃ´nomos (seguem G1 via Lidar)
â€¢ Sistema WMS integrado

Resultados (1 ano):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Produtividade: +40% vs humano
âœ… AcurÃ¡cia: 99.2% (vs 95% humano)
âœ… Trabalham 22h/dia (2h manutenÃ§Ã£o/carga)
âœ… Custo: $0.80/hora (vs $8/hora humano)
```

**LimitaÃ§Ãµes:**
- âŒ Payload 3kg (sÃ³ produtos leves - eletrÃ´nicos, livros)
- âŒ Requer estantes padronizadas (acessibilidade)
- âœ… **Para payloads maiores, usar Agility Digit**

</TabItem>

<TabItem value="hospitality" label="Hospitalidade">

**Hotel:** Hyatt Regency (TÃ³quio, JapÃ£o)
**AplicaÃ§Ã£o:** Concierge robÃ³tico

```
ServiÃ§os Oferecidos:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Guiar hÃ³spedes atÃ© quarto
   â€¢ Carrega 1 mala (3kg max)
   â€¢ Conversa durante trajeto (LLM)

2. Room service delivery
   â€¢ Comida/bebidas leves
   â€¢ Bate na porta, espera hÃ³spede abrir

3. InformaÃ§Ãµes turÃ­sticas
   â€¢ "Onde fica a estaÃ§Ã£o de metrÃ´?"
   â€¢ Mostra mapa no tablet preso ao torso

4. Entretenimento (lobby)
   â€¢ Dance performances
   â€¢ Tira selfies com crianÃ§as

Feedback HÃ³spedes (6 meses):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â­â­â­â­â­ (4.7/5.0)
â€¢ "Muito fofo!"
â€¢ "CrianÃ§as adoraram"
â€¢ "Pontual (vs humanos)"
â€¢ CrÃ­tica: "Ainda um pouco lento"

Impacto NegÃ³cio:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… MenÃ§Ãµes na mÃ­dia (+20% reservas)
âœ… Instagram/TikTok viralizaÃ§Ã£o
âœ… ReduÃ§Ã£o custo operacional (-10%)
```

</TabItem>
</Tabs>

---

## ğŸ“ EducaÃ§Ã£o

### Cursos UniversitÃ¡rios com G1

<Tabs>
<TabItem value="mit" label="MIT Course">

**Curso:** 6.8210 - Underactuated Robotics
**Professor:** Russ Tedrake (Toyota Research Institute)

```
Estrutura do Curso (12 semanas):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Semanas 1-4: Teoria
â”œâ”€ DinÃ¢mica de sistemas robÃ³ticos
â”œâ”€ Controle Ã³timo (LQR, MPC)
â””â”€ Stabilization de sistemas underactuated

Semanas 5-8: SimulaÃ§Ã£o
â”œâ”€ Modelagem G1 em Drake (Python)
â”œâ”€ Implementar controlador
â””â”€ Testar em sim (Gazebo)

Semanas 9-12: Hardware (G1 real!)
â”œâ”€ Transferir controlador para G1
â”œâ”€ Refinar com dados reais
â””â”€ Projeto final: Caminhada em terreno inclinado

Projeto Final (grupos de 3):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Objetivo: G1 andar em rampa 15Â° sem cair

AvaliaÃ§Ã£o:
â€¢ 40% - Estabilidade (nÃ£o cai)
â€¢ 30% - EficiÃªncia energÃ©tica
â€¢ 20% - Velocidade
â€¢ 10% - RelatÃ³rio tÃ©cnico

Exemplo vencedor (2024):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Team: "Bipedal Wizards"
Abordagem: MPC com prediÃ§Ã£o de terreno via LIDAR
Resultado:
âœ… 15Â° rampa, sem quedas (20 tentativas)
âœ… 0.8 m/s velocidade mantida
âœ… 15% menos energia que baseline
```

</TabItem>

<TabItem value="usp" label="USP - Projeto">

**Disciplina:** PMR3401 - RobÃ³tica MÃ³vel
**Universidade de SÃ£o Paulo - Escola PolitÃ©cnica**

```
Projeto Semestral:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"Sistema de NavegaÃ§Ã£o AutÃ´noma Indoor"

Etapas:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Mapeamento (SLAM)
   â””â”€ Mapear laboratÃ³rio com LIDAR
   â””â”€ Criar mapa 2D ocupancy grid

2. LocalizaÃ§Ã£o (AMCL)
   â””â”€ Localizar robÃ´ no mapa
   â””â”€ Filtro de partÃ­culas

3. Planejamento (Nav2)
   â””â”€ Planejar caminho livre de obstÃ¡culos
   â””â”€ A* + DWA planner

4. Controle
   â””â”€ Seguir trajetÃ³ria
   â””â”€ Evitar obstÃ¡culos dinÃ¢micos

5. DemonstraÃ§Ã£o Final
   â””â”€ RobÃ´ navega de sala A â†’ sala B
   â””â”€ Evita pessoas andando
   â””â”€ Chega em &lt;5 min

Ferramentas:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ROS2 Humble
â€¢ Nav2 stack
â€¢ Gazebo (sim) + G1 (hardware)
â€¢ Python/C++

Resultado TÃ­pico:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Taxa de sucesso: 85%
Tempo mÃ©dio: 3.5 min
ColisÃµes: &lt;1% das tentativas
```

</TabItem>

<TabItem value="high-school" label="Ensino MÃ©dio">

**Programa:** FIRST Robotics (adaptado para humanoides)
**Local:** EUA, alguns times elite

```
CompetiÃ§Ã£o: "Humanoid Helper Challenge"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Objetivo: RobÃ´ completa tarefas domÃ©sticas

Tarefas (pontos):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Pegar objeto de mesa (10 pts)
2. Colocar objeto em cesta (15 pts)
3. Abrir porta (20 pts) â† DifÃ­cil!
4. Subir 1 degrau (25 pts)
5. Autonomia (+10 pts se 100% autÃ´nomo)

RestriÃ§Ãµes:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 3 minutos total
â€¢ Budget: $30k (G1 EDU cabe!)
â€¢ Safety: E-stop sempre acessÃ­vel

Times Participantes (2024):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 12 times (USA)
â€¢ Maioria usa G1 EDU ($16k)
â€¢ Alguns usam Digit ($$$)

Vencedor 2024:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Team 9999 - "BipedBots"
PontuaÃ§Ã£o: 68/70 pts
EstratÃ©gia:
â€¢ Treinou rede neural em sim (1M episodes)
â€¢ Transferiu para G1 real
â€¢ 95% autonomia

Impacto Estudantes:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"G1 deixou robÃ³tica humanoide acessÃ­vel para high school.
Antes, sÃ³ faculdades tinham verba." - Mentor Team 9999
```

</TabItem>
</Tabs>

---

## ğŸŒŸ Casos Emergentes

### AplicaÃ§Ãµes Inovadoras

<Tabs>
<TabItem value="art" label="Arte e Performance">

**Artista:** Huang Yi (Taiwan)
**Projeto:** "Human + G1 Contemporary Dance"

```
Coreografia:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Humano danÃ§arino + G1 sincronizados
â€¢ G1 segue movimentos via motion capture
â€¢ LatÃªncia < 100ms

Setup TÃ©cnico:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Vicon MoCap (30 cÃ¢meras IR)
2. Captura esqueleto humano (realtime)
3. Mapeia para joints do G1
4. G1 replica movimentos

Performances:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Taipei Arts Festival 2024
â€¢ 800+ espectadores
â€¢ Standing ovation

CrÃ­tica:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"Mesmerizante ver humano e mÃ¡quina
em harmonia perfeita. Questiona
o que significa ser humano."
- NY Times Arts Review
```

</TabItem>

<TabItem value="elderly" label="Cuidado de Idosos">

**Projeto Piloto:** Silver Care (JapÃ£o)
**Parceiro:** Ministry of Health, Labour and Welfare

```
Problema:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ JapÃ£o: 28% populaÃ§Ã£o &lt;65 anos
â€¢ Falta de cuidadores (aging population)
â€¢ Idosos isolados em casa

SoluÃ§Ã£o com G1:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Companhia
   â€¢ Conversa (LLM em japonÃªs)
   â€¢ Joga shogi (xadrez japonÃªs)
   â€¢ Lembra de tomar remÃ©dios

2. AssistÃªncia FÃ­sica
   â€¢ Pega objetos que caÃ­ram
   â€¢ Traz copo d'Ã¡gua
   â€¢ Abre porta para visitantes

3. Monitoramento
   â€¢ Detecta quedas (cÃ¢mera)
   â€¢ Alerta famÃ­lia se anomalia
   â€¢ Telemetria para enfermeiros

Piloto (50 lares, 6 meses):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SatisfaÃ§Ã£o: 78% idosos "muito satisfeitos"
ReduÃ§Ã£o solidÃ£o: -40% (escala UCLA)
Incidentes: 2 quedas detectadas, ajuda solicitada

Desafios:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Interface simples (idosos nÃ£o tech-savvy)
â€¢ ConfianÃ§a (medo de robÃ´s)
â€¢ Custo ($27k ainda caro para maioria)

Futuro:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Governo subsÃ­dio planejado:
$15k/unidade para famÃ­lias baixa renda
Meta: 10,000 unidades atÃ© 2027
```

</TabItem>

<TabItem value="space" label="Treinamento Espacial">

**AgÃªncia:** ESA (European Space Agency)
**Projeto:** Mars Analog Mission

```
Objetivo:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Testar humanoides para missÃµes Marte/Lua

Por Que Humanoides?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Ferramentas projetadas para humanos
â€¢ VeÃ­culos/habitats antropomÃ³rficos
â€¢ Backup para astronautas

Setup:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Base anÃ¡loga Marte (deserto Nevada)
â€¢ G1 com upgrade:
  â”œâ”€ Dust-resistant (IP54)
  â”œâ”€ Temperatura extrema (-40Â°C a +60Â°C)
  â”œâ”€ Solar panel backpack (+2h autonomia)
  â””â”€ Satcom antenna (simula delay Terra-Marte)

Tarefas Testadas:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Coletar amostras geolÃ³gicas
2. Reparar painel solar (manipulaÃ§Ã£o)
3. Caminhar 5km (navegaÃ§Ã£o longa distÃ¢ncia)
4. Entrar/sair rover (mobilidade)

Resultados (preliminares):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… 3/4 tarefas completadas
âŒ Entrar rover: Falhou (espaÃ§o apertado)
âš ï¸ Bateria: Requer swaps a cada 3h

ConclusÃ£o ESA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"Humanoides promissores mas ainda
5-10 anos de desenvolvimento para
missÃµes reais. G1 Ã© excelente
plataforma de pesquisa."
```

</TabItem>
</Tabs>

---

## ğŸ“Š ROI e Viabilidade

### AnÃ¡lise de Custo-BenefÃ­cio

```python
# roi_calculator.py

def calculate_roi(
    robot_cost=27500,  # USD
    yearly_operating_cost=5000,  # ManutenÃ§Ã£o, energia, peÃ§as
    yearly_benefit=35000,  # Economia vs humano
):
    """
    Calcula ROI do G1 para aplicaÃ§Ã£o industrial
    """

    payback_years = robot_cost / (yearly_benefit - yearly_operating_cost)
    roi_5years = ((yearly_benefit * 5) - robot_cost - (yearly_operating_cost * 5)) / robot_cost * 100

    print(f"ğŸ“Š ROI ANALYSIS")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"Investimento inicial: ${robot_cost:,}")
    print(f"Custo operacional/ano: ${yearly_operating_cost:,}")
    print(f"BenefÃ­cio/ano: ${yearly_benefit:,}")
    print(f"BenefÃ­cio lÃ­quido/ano: ${yearly_benefit - yearly_operating_cost:,}")
    print(f"")
    print(f"Payback period: {payback_years:.1f} anos")
    print(f"ROI (5 anos): {roi_5years:.0f}%")

    return payback_years, roi_5years

# Exemplo: Warehouse picking
calculate_roi(
    robot_cost=27500,
    yearly_operating_cost=5000,  # Energia + manutenÃ§Ã£o
    yearly_benefit=50000,  # Substitui 1 operador humano ($25/h * 2000h)
)

# Output:
# Payback period: 0.6 anos (7 meses!)
# ROI (5 anos): 718%
```

---

## âœ… Checklist de Conhecimento

ApÃ³s este mÃ³dulo, vocÃª deve saber:

- [ ] G1 usado em 50+ universidades globalmente
- [ ] AplicaÃ§Ãµes industriais: InspeÃ§Ã£o, warehouse, hospitalidade
- [ ] EducaÃ§Ã£o: MIT usa em curso avanÃ§ado, USP em robÃ³tica mÃ³vel
- [ ] Casos emergentes: Arte, cuidado idosos, treinamento espacial
- [ ] ROI tÃ­pico: 12-24 meses para aplicaÃ§Ãµes industriais
- [ ] LimitaÃ§Ã£o principal: Payload 3kg (para mais, usar Digit/Figure)

---

## ğŸ”— PrÃ³ximos Passos

:::tip PrÃ³ximo MÃ³dulo
**[ğŸ”® Futuro e Roadmap â†’](./futuro-roadmap)**

MindOn OS, prÃ³ximas geraÃ§Ãµes do G1 e futuro da robÃ³tica humanoide.
:::

---

**â±ï¸ Tempo de estudo:** 35-45 minutos
**ğŸ“Š NÃ­vel:** IntermediÃ¡rio
**ğŸ’¡ InspiraÃ§Ã£o:** Casos reais para seu projeto!
