---
sidebar_position: 4
title: 4. Sistema Computacional
description: Jetson Orin NX, processamento e IA
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ğŸ–¥ï¸ Sistema Computacional

:::tip Objetivo
Entender o computador embarcado do G1: Jetson Orin NX, arquitetura, ROS2, processamento de IA e otimizaÃ§Ãµes.
:::

---

## ğŸ§  NVIDIA Jetson Orin NX 16GB

### Arquitetura do SoM (System on Module)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       NVIDIA Jetson Orin NX 16GB SOM           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CPU: 8-core ARM Cortex-A78AE @ 2.0 GHz       â”‚
â”‚  â”œâ”€ 4x Big cores (high performance)            â”‚
â”‚  â””â”€ 4x Little cores (energy efficient)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPU: 1024-core NVIDIA Ampere                  â”‚
â”‚  â”œâ”€ 32 Tensor Cores (IA acelerada)             â”‚
â”‚  â”œâ”€ 8 RT Cores (raytracing - nÃ£o usado)        â”‚
â”‚  â””â”€ 100 TOPS (INT8) / 50 TFLOPS (FP16)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Memory: 16GB LPDDR5                            â”‚
â”‚  â”œâ”€ Bandwidth: 102 GB/s                        â”‚
â”‚  â””â”€ Shared entre CPU/GPU (unified memory)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage: 64GB eMMC (sistema)                  â”‚
â”‚  â””â”€ Slot NVMe M.2 para expansÃ£o (atÃ© 2TB)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conectividade:                                 â”‚
â”‚  â”œâ”€ 2x GbE (Gigabit Ethernet)                  â”‚
â”‚  â”œâ”€ 4x USB 3.2                                 â”‚
â”‚  â”œâ”€ HDMI 2.1 (debug/desenvolvimento)           â”‚
â”‚  â”œâ”€ 3x MIPI CSI-2 (cÃ¢meras)                    â”‚
â”‚  â”œâ”€ 2x CAN Bus                                 â”‚
â”‚  â””â”€ GPIO, I2C, SPI, UART                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Power: 10-25W (configurÃ¡vel)                  â”‚
â”‚  OS: Ubuntu 20.04 (JetPack 5.1.2)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Por Que Jetson Orin NX?

<Tabs>
<TabItem value="ai" label="IA Acelerada">

**100 TOPS de Performance**

TOPS = Tera Operations Per Second (trilhÃµes ops/seg)

```python
# Exemplo: YOLO detection com GPU
import tensorrt as trt

# Modelo YOLO otimizado para Jetson
model = trt.load_engine('yolov8n_fp16.trt')

# Inference em uma imagem 1920x1080
frame = camera.read()
detections = model.infer(frame)  # ~3ms (333 FPS!)

# Mesmo modelo sem GPU: ~150ms (6 FPS)
# AceleraÃ§Ã£o: 50x mais rÃ¡pido
```

**AplicaÃ§Ãµes que Usam 100 TOPS:**
1. **VisÃ£o Computacional** (40 TOPS)
   - YOLO object detection
   - Pose estimation (detectar pessoas)
   - Depth estimation

2. **NavegaÃ§Ã£o** (30 TOPS)
   - SLAM (mapeamento simultÃ¢neo)
   - Path planning
   - Obstacle avoidance

3. **Controle** (20 TOPS)
   - Modelo preditivo de estabilidade
   - OtimizaÃ§Ã£o de marcha em tempo real

4. **Reserva** (10 TOPS)
   - Tarefas customizadas do usuÃ¡rio

</TabItem>

<TabItem value="comparison" label="ComparaÃ§Ã£o">

**Jetson Orin NX vs Alternativas:**

| Plataforma | TOPS | CPU | RAM | PreÃ§o | Consumo |
|------------|------|-----|-----|-------|---------|
| **Orin NX 16GB** | 100 | 8-core A78 | 16GB | $800 | 10-25W |
| Orin Nano 8GB | 40 | 6-core A78 | 8GB | $500 | 7-15W |
| Orin AGX 64GB | 275 | 12-core A78 | 64GB | $2000 | 15-60W |
| Xavier NX | 21 | 6-core Carmel | 16GB | $400 | 10-20W |
| Raspberry Pi 5 | ~2 | 4-core A76 | 8GB | $80 | 5W |
| Intel NUC i7 | ~5 | x86 i7 | 32GB | $1200 | 30-65W |

**Por que NX Ã© ideal para G1:**
- âœ… Balance perfeito: performance/custo/energia
- âœ… 16GB suficiente para mÃºltiplos modelos IA simultÃ¢neos
- âœ… CompatÃ­vel com ROS2 nativo (ARM)
- âœ… Ecossistema maduro (JetPack, TensorRT)

</TabItem>

<TabItem value="power-modes" label="Modos de Energia">

**NVP Model (NVIDIA Power Model):**

```bash
# Listar modos disponÃ­veis
sudo nvpmodel -q

Available modes:
- Mode 0: MAXN (max performance) - 25W
- Mode 1: 15W - balanced
- Mode 2: 10W - power save

# G1 usa Mode 1 (15W) por padrÃ£o
sudo nvpmodel -m 1

# Para desenvolvimento intenso, usar MAXN
sudo nvpmodel -m 0
```

**ComparaÃ§Ã£o de Performance:**

| Modo | CPU Max | GPU Max | RAM BW | TOPS | Uso |
|------|---------|---------|--------|------|-----|
| MAXN (25W) | 2.0GHz | 918MHz | 102GB/s | 100 | Desenvolvimento |
| 15W | 1.5GHz | 765MHz | 85GB/s | 70 | **ProduÃ§Ã£o (G1)** |
| 10W | 1.2GHz | 624MHz | 68GB/s | 50 | Economia extrema |

**Quando Trocar:**
```python
# Detectar carga de trabalho
if heavy_ai_task:
    os.system('sudo nvpmodel -m 0')  # MAXN
else:
    os.system('sudo nvpmodel -m 1')  # Default
```

</TabItem>
</Tabs>

---

## ğŸ§ Sistema Operacional

### Ubuntu 20.04 + JetPack 5.1.2

**O que vem instalado:**

```
â”Œâ”€ Base System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ubuntu 20.04.6 LTS (Focal Fossa)  â”‚
â”‚ Kernel: 5.10.104-tegra            â”‚
â”‚ Python: 3.8.10                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ NVIDIA JetPack 5.1.2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CUDA 11.4                          â”‚
â”‚ cuDNN 8.6                          â”‚
â”‚ TensorRT 8.5.2                     â”‚
â”‚ VPI (Vision Programming Interface) â”‚
â”‚ DeepStream SDK 6.2                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ROS & Robotics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ROS2 Humble (LTS)                  â”‚
â”‚ Gazebo 11                          â”‚
â”‚ MoveIt 2                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ AI Frameworks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PyTorch 1.13 (ARM + CUDA)          â”‚
â”‚ TensorFlow 2.11                    â”‚
â”‚ ONNX Runtime 1.14                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Acesso ao Sistema

<Tabs>
<TabItem value="ssh" label="SSH">

**Conectar via WiFi/Ethernet:**

```bash
# G1 cria hotspot WiFi quando ligado
SSID: Unitree-G1-XXXX
Password: (fornecida com robÃ´)

# IP padrÃ£o: 192.168.123.1

# SSH
ssh unitree@192.168.123.1
# Senha padrÃ£o: 123

# Trocar senha
passwd
```

**Desenvolvimento Remoto:**
```bash
# VS Code Remote SSH
# Instalar extensÃ£o: Remote - SSH

# .ssh/config
Host unitree-g1
    HostName 192.168.123.1
    User unitree
    ForwardX11 yes  # Para GUIs

# Conectar
code --remote ssh-remote+unitree-g1 /home/unitree/workspace
```

</TabItem>

<TabItem value="monitor" label="Monitor Direto">

**Conectar HDMI + USB:**

```
G1 possui:
â”œâ”€ Porta HDMI (lado torso)
â”œâ”€ Porta USB (teclado/mouse)
â””â”€ Boot direto para Ubuntu Desktop

Uso: Debugging, setup inicial
NÃ£o recomendado para operaÃ§Ã£o (cabos limitam movimento)
```

</TabItem>

<TabItem value="jupyter" label="Jupyter Notebook">

**Desenvolvimento Interativo:**

```bash
# No G1 via SSH
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser

# No seu PC
# Acessar: http://192.168.123.1:8888

# Token aparece no terminal do G1
```

**Exemplo - Testar CÃ¢mera:**
```python
# Jupyter cell
import cv2
from unitree_sdk import Robot

robot = Robot()
frame = robot.camera_front.read()

# Mostrar inline
from IPython.display import Image, display
_, encoded = cv2.imencode('.jpg', frame)
display(Image(data=encoded.tobytes()))
```

</TabItem>
</Tabs>

---

## ğŸ¤– ROS2 Humble

### Arquitetura ROS2 no G1

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ROS2 Nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  /camera_node â†’ /camera/image_raw (topic)       â”‚
â”‚       â†“                                         â”‚
â”‚  /yolo_detector â†’ /detections (topic)           â”‚
â”‚       â†“                                         â”‚
â”‚  /navigation â†’ /cmd_vel (topic) â†’ Motores       â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Nodes Principais do G1

<Tabs>
<TabItem value="sensors" label="Sensor Nodes">

```bash
# Listar nodes ativos
ros2 node list

/lidar_node          # Publica point clouds
/camera_front_node   # CÃ¢mera principal
/camera_left_node    # Stereo esquerda
/camera_right_node   # Stereo direita
/imu_node            # IMU (acelerÃ´metro + gyro)
/joint_state_node    # PosiÃ§Ãµes de todos motores
```

**Exemplo - Ler CÃ¢mera:**
```bash
# Ver imagem (requer X11 forwarding)
ros2 run image_tools showimage --ros-args \
  -r image:=/camera/front/image_raw

# Salvar frame
ros2 run image_view image_saver --ros-args \
  -r image:=/camera/front/image_raw
```

</TabItem>

<TabItem value="control" label="Control Nodes">

```bash
/locomotion_controller    # Controle de caminhada
/arm_left_controller      # BraÃ§o esquerdo
/arm_right_controller     # BraÃ§o direito
/balance_controller       # EstabilizaÃ§Ã£o
/gait_planner             # Planejamento de marcha
```

**Comandar Movimento:**
```bash
# Caminhar para frente a 0.5 m/s
ros2 topic pub --once /cmd_vel geometry_msgs/Twist \
  "{linear: {x: 0.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.0}}"

# Girar (0.5 rad/s)
ros2 topic pub --once /cmd_vel geometry_msgs/Twist \
  "{linear: {x: 0.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.5}}"
```

</TabItem>

<TabItem value="ai" label="AI Nodes">

```python
# Node customizado - YOLO detector
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from vision_msgs.msg import Detection2DArray
from cv_bridge import CvBridge
import cv2
import tensorrt as trt

class YOLODetector(Node):
    def __init__(self):
        super().__init__('yolo_detector')

        # Subscriber para cÃ¢mera
        self.sub = self.create_subscription(
            Image,
            '/camera/front/image_raw',
            self.image_callback,
            10
        )

        # Publisher para detecÃ§Ãµes
        self.pub = self.create_publisher(
            Detection2DArray,
            '/detections',
            10
        )

        self.bridge = CvBridge()
        self.model = trt.load_engine('yolov8n.trt')

    def image_callback(self, msg):
        # Converter ROS Image -> OpenCV
        cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')

        # InferÃªncia
        detections = self.model.infer(cv_image)

        # Publicar detecÃ§Ãµes
        detection_msg = self.format_detections(detections)
        self.pub.publish(detection_msg)

def main():
    rclpy.init()
    node = YOLODetector()
    rclpy.spin(node)

if __name__ == '__main__':
    main()
```

</TabItem>
</Tabs>

---

## âš¡ OtimizaÃ§Ãµes de Performance

### TensorRT - OtimizaÃ§Ã£o de Modelos IA

**Converter PyTorch â†’ TensorRT:**

```python
import torch
import torch_tensorrt

# Modelo PyTorch original
model = torch.hub.load('ultralytics/yolov8', 'yolov8n')
model.eval().cuda()

# Converter para TensorRT
trt_model = torch_tensorrt.compile(
    model,
    inputs=[torch_tensorrt.Input(shape=[1, 3, 640, 640])],
    enabled_precisions={torch.float16},  # FP16 (2x mais rÃ¡pido)
)

# Salvar
torch.jit.save(trt_model, 'yolov8n_fp16.ts')
```

**Ganhos de Performance:**

| Modelo | Framework | Precision | FPS | LatÃªncia |
|--------|-----------|-----------|-----|----------|
| YOLOv8n | PyTorch | FP32 | 15 | 66ms |
| YOLOv8n | PyTorch | FP16 | 28 | 35ms |
| YOLOv8n | **TensorRT** | **FP16** | **120** | **8ms** |
| YOLOv8s | TensorRT | FP16 | 60 | 16ms |

---

### Unified Memory - Zero-Copy

**Jetson usa memÃ³ria compartilhada CPUâ†”GPU:**

```python
import cupy as cp  # NumPy-like para CUDA
import numpy as np

# âŒ MÃ©todo tradicional (com cÃ³pia)
data_cpu = np.random.rand(1920, 1080, 3).astype(np.uint8)
data_gpu = cp.array(data_cpu)  # Copia CPUâ†’GPU (lento!)

# âœ… MÃ©todo Jetson (zero-copy)
import pycuda.driver as cuda

# Alocar em unified memory
data_unified = cuda.managed_empty(
    shape=(1920, 1080, 3),
    dtype=np.uint8,
    mem_flags=cuda.mem_attach_flags.GLOBAL
)

# CPU e GPU acessam MESMA memÃ³ria
# Sem cÃ³pia, 10x mais rÃ¡pido para grandes dados
```

---

### Cooling e Throttling

**Monitorar Temperatura:**

```bash
# Ver temperaturas
tegrastats

# Output:
# CPU@38.5Â°C GPU@42Â°C ...
```

**Cooling Ativo:**
```
G1 possui:
â”œâ”€ 2x Ventiladores 40mm (torso)
â”œâ”€ PWM controlado (0-100%)
â””â”€ Trigger: &lt;60Â°C = 100% fan

ConfiguraÃ§Ã£o:
/etc/nvidia/nvfancontrol.conf
```

**Evitar Thermal Throttling:**
```python
# Monitorar clock real vs max
import subprocess

def get_gpu_clock():
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=clocks.gr', '--format=csv,noheader,nounits'],
        capture_output=True,
        text=True
    )
    return int(result.stdout.strip())

clock = get_gpu_clock()
if clock < 900:  # Max: 918 MHz em mode MAXN
    print(f"âš ï¸ Throttling detectado! Clock: {clock} MHz")
    print("GPU muito quente, reduzir carga de trabalho")
```

---

## ğŸ“¦ ExpansÃ£o de Armazenamento

### Adicionar SSD NVMe

**Slot M.2 2280 disponÃ­vel:**

```bash
# Recomendado: Samsung 980 PRO 512GB
# Custo: ~$80

# 1. Instalar fisicamente (parafuso M2)
# 2. Formatar
sudo mkfs.ext4 /dev/nvme0n1

# 3. Montar automaticamente
sudo mkdir /mnt/nvme
echo "/dev/nvme0n1 /mnt/nvme ext4 defaults 0 2" | sudo tee -a /etc/fstab

# 4. Mover datasets/models para SSD
mv ~/datasets /mnt/nvme/
ln -s /mnt/nvme/datasets ~/datasets
```

**BenefÃ­cios:**
- ğŸ“¦ 500GB+ espaÃ§o (vs 64GB eMMC)
- âš¡ 3000 MB/s leitura (vs 300 MB/s eMMC)
- ğŸ¥ Gravar vÃ­deos das cÃ¢meras
- ğŸ’¾ Armazenar logs/telemetria

---

## âœ… Checklist de Conhecimento

ApÃ³s este mÃ³dulo, vocÃª deve saber:

- [ ] Specs do Jetson Orin NX (8-core CPU, 1024 GPU cores, 16GB RAM)
- [ ] O que sÃ£o 100 TOPS e para que servem
- [ ] Como conectar via SSH ao G1
- [ ] ROS2 Humble Ã© o middleware padrÃ£o
- [ ] TensorRT otimiza modelos IA (8x speedup)
- [ ] Como expandir armazenamento com NVMe

---

## ğŸ”— PrÃ³ximos Passos

:::tip PrÃ³ximo MÃ³dulo
**[ğŸ“¡ ComunicaÃ§Ã£o e Conectividade â†’](./comunicacao-conectividade)**

Redes, WiFi, 4G, API remota e multi-robÃ´.
:::

---

**â±ï¸ Tempo de estudo:** 50-60 minutos
**ğŸ“Š NÃ­vel:** IntermediÃ¡rio-AvanÃ§ado
**ğŸ’» Hands-on:** SSH ao G1, explorar ROS2 topics
