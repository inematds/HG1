---
sidebar_position: 3
title: 3. Interfaces de Controle
description: Joystick, VR, tablets e comandos de voz para operar humanoides
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# üïπÔ∏è Interfaces de Controle para Humanoides

:::tip Objetivo do M√≥dulo
Dominar as principais formas de controlar um rob√¥ humanoide: desde joysticks tradicionais at√© realidade virtual e comandos de voz.
:::

---

## üéÆ Tipos de Interface de Controle

### Compara√ß√£o Geral

| Interface | Precis√£o | Lat√™ncia | Curva de Aprendizado | Custo | Melhor Para |
|-----------|----------|----------|----------------------|-------|-------------|
| **Teclado** | Baixa | Baixa (10ms) | F√°cil | $0 | Testes iniciais |
| **Joystick Gamepad** | M√©dia | Baixa (15ms) | F√°cil | $30-60 | Opera√ß√£o geral |
| **Joystick Profissional** | Alta | Baixa (5ms) | Moderada | $200-500 | Tarefas de precis√£o |
| **SpaceMouse** | Muito Alta | Baixa (5ms) | Dif√≠cil | $150-400 | Manipula√ß√£o 6-DOF |
| **Tablet Touchscreen** | M√©dia | M√©dia (50ms) | F√°cil | $300-1000 | Supervis√£o mobile |
| **VR (Realidade Virtual)** | Muito Alta | M√©dia (30ms) | Dif√≠cil | $300-1500 | Teleopera√ß√£o imersiva |
| **Comandos de Voz** | Baixa | Alta (200ms) | F√°cil | $0 | Comandos de alto n√≠vel |
| **Motion Capture** | Alt√≠ssima | Baixa (10ms) | Dif√≠cil | $5k+ | Imita√ß√£o de movimentos |

---

## ‚å®Ô∏è Controle por Teclado

### Quando Usar

- ‚úÖ Testes r√°pidos em simula√ß√£o
- ‚úÖ Aprender comandos b√°sicos
- ‚úÖ Desenvolvimento de software (debug)
- ‚ùå **NUNCA** em hardware real (muito impreciso)

### Mapeamento B√°sico ROS2

<Tabs>
<TabItem value="teleop-twist" label="üö∂ Movimento Base">

**Pacote:** `teleop_twist_keyboard`

```bash
# Instalar
sudo apt install ros-humble-teleop-twist-keyboard

# Executar
ros2 run teleop_twist_keyboard teleop_twist_keyboard
```

**Teclas Padr√£o:**
```
        i      (frente)
   j    k    l (esquerda, parar, direita)
        ,      (tr√°s)

u  o   (girar enquanto anda)
m  .   (girar enquanto anda para tr√°s)

q/z : Aumentar/diminuir velocidade linear (10%)
w/x : Aumentar/diminuir velocidade angular (10%)

CTRL-C para sair
```

</TabItem>
<TabItem value="joint-control" label="ü¶æ Controle de Juntas">

**Script Python Customizado:**

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
import sys
import termios
import tty

class KeyboardJointControl(Node):
    def __init__(self):
        super().__init__('keyboard_joint_control')
        self.publisher = self.create_publisher(JointState, '/joint_commands', 10)

        # Estado atual das juntas
        self.joint_positions = {
            'left_shoulder': 0.0,
            'right_shoulder': 0.0,
            'left_knee': 0.0,
            'right_knee': 0.0,
        }

        self.current_joint = 'left_shoulder'
        self.step = 0.1  # radianos por tecla

    def get_key(self):
        """Captura uma tecla sem esperar Enter"""
        fd = sys.stdin.fileno()
        old_settings = termios.tcgetattr(fd)
        try:
            tty.setraw(sys.stdin.fileno())
            key = sys.stdin.read(1)
        finally:
            termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
        return key

    def process_key(self, key):
        if key == 'w':  # Aumentar √¢ngulo
            self.joint_positions[self.current_joint] += self.step
        elif key == 's':  # Diminuir √¢ngulo
            self.joint_positions[self.current_joint] -= self.step
        elif key == '1':  # Selecionar junta
            self.current_joint = 'left_shoulder'
        elif key == '2':
            self.current_joint = 'right_shoulder'
        elif key == '3':
            self.current_joint = 'left_knee'
        elif key == '4':
            self.current_joint = 'right_knee'
        elif key == 'q':  # Sair
            return False

        # Publicar novo estado
        msg = JointState()
        msg.name = list(self.joint_positions.keys())
        msg.position = list(self.joint_positions.values())
        self.publisher.publish(msg)

        print(f'Junta: {self.current_joint} | √Çngulo: {self.joint_positions[self.current_joint]:.2f} rad')
        return True

    def run(self):
        print("=== Controle de Juntas por Teclado ===")
        print("1/2/3/4: Selecionar junta")
        print("W/S: Aumentar/Diminuir √¢ngulo")
        print("Q: Sair\n")

        running = True
        while running:
            key = self.get_key()
            running = self.process_key(key)

def main():
    rclpy.init()
    node = KeyboardJointControl()
    node.run()
    rclpy.shutdown()
```

</TabItem>
</Tabs>

---

## üéÆ Joystick Gamepad (Xbox/PlayStation)

### Hardware Recomendado

<Tabs>
<TabItem value="budget" label="üí∞ Entrada ($30-60)">

**Xbox One Controller (com fio)**
- **Pre√ßo:** $40 (Amazon)
- **Conex√£o:** USB
- **Lat√™ncia:** ~15ms
- **Compatibilidade:** Linux nativo (driver `xpad`)

**Configura√ß√£o:**
```bash
# Verificar se foi detectado
sudo apt install joystick
jstest /dev/input/js0

# Instalar pacote ROS2
sudo apt install ros-humble-joy
sudo apt install ros-humble-teleop-twist-joy
```

</TabItem>
<TabItem value="mid" label="üöÄ Intermedi√°rio ($60-150)">

**PlayStation 5 DualSense**
- **Pre√ßo:** $70
- **Conex√£o:** USB-C ou Bluetooth
- **Lat√™ncia:** ~10ms (USB), ~20ms (BT)
- **Extras:** Feedback h√°ptico avan√ßado, gatilhos adaptativos

**Vantagens:**
- ‚úÖ Gatilhos anal√≥gicos (melhor controle de velocidade)
- ‚úÖ Feedback t√°til (sentir colis√µes no jogo)
- ‚úÖ Bateria interna (uso sem fio)

**Driver Linux:**
```bash
# Instalar suporte PS5
sudo apt install ds5-tool
```

</TabItem>
<TabItem value="pro" label="üíé Profissional ($200-500)">

**Logitech Extreme 3D Pro (Joystick de Voo)**
- **Pre√ßo:** $40 (mas design profissional)
- **Conex√£o:** USB
- **Controles:** 1 stick 3-axis + 12 bot√µes + throttle
- **Uso:** Controle fino de movimentos (bra√ßos, c√¢mera)

**Thrustmaster HOTAS (Hands On Throttle And Stick)**
- **Pre√ßo:** $250-500
- **Controles:** 2 sticks independentes + pedais (opcional)
- **Uso:** Teleopera√ß√£o avan√ßada (uma m√£o = movimento, outra = bra√ßos)

</TabItem>
</Tabs>

### Configura√ß√£o ROS2 Joy

**Arquivo de configura√ß√£o:** `config/joy_teleop.yaml`

```yaml
teleop_twist_joy_node:
  ros__parameters:
    # Eixos do joystick (valores de 0 a N, conforme seu controle)
    axis_linear:  1   # Stick esquerdo vertical (frente/tr√°s)
    axis_angular: 2   # Stick direito horizontal (girar)

    # Escala de velocidade
    scale_linear: 1.0   # m/s m√°ximo
    scale_angular: 2.0  # rad/s m√°ximo

    # Bot√£o "turbo" (segurar para velocidade m√°xima)
    enable_button: 5    # Bot√£o RB (bumper direito)

    # Bot√£o "slow mode" (precis√£o)
    enable_turbo_button: 4  # Bot√£o LB (bumper esquerdo)
```

**Lan√ßar n√≥:**
```bash
ros2 launch teleop_twist_joy teleop-launch.py joy_config:='xbox'
```

### Mapeamento Avan√ßado para Humanoides

```yaml
# Exemplo: Controlar Unitree H1
humanoid_teleop:
  ros__parameters:
    # Movimento da base
    axis_walk_forward: 1   # Stick esquerdo Y
    axis_walk_strafe: 0    # Stick esquerdo X
    axis_turn: 2           # Stick direito X

    # Controle de altura (agachar)
    axis_height: 5         # Gatilhos L2/R2 (analogicos)

    # Bra√ßos
    button_arm_mode: 3     # Bot√£o Y (alternar modo bra√ßo)
    axis_left_arm_x: 0     # Stick esquerdo X (quando em modo bra√ßo)
    axis_left_arm_y: 1     # Stick esquerdo Y

    # Comandos discretos
    button_stand: 0        # A (posi√ß√£o neutra)
    button_sit: 1          # B (sentar)
    button_wave: 2         # X (acenar)
    button_emergency_stop: 6  # Bot√£o central esquerdo (E-STOP)

    # Sensibilidade
    deadzone: 0.1          # Zona morta (evitar drift)
    max_linear_vel: 1.5    # m/s
    max_angular_vel: 1.0   # rad/s
```

---

## üñ±Ô∏è SpaceMouse (Controle 6-DOF)

### O Que √© 6-DOF?

**6 Degrees of Freedom (6 Graus de Liberdade):**
- **Transla√ß√£o:** X, Y, Z (mover nos 3 eixos)
- **Rota√ß√£o:** Roll, Pitch, Yaw (girar nos 3 eixos)

**Exemplo de Uso:**
- Controlar **m√£o do rob√¥** no espa√ßo 3D
- Posicionar **c√¢mera** da cabe√ßa do rob√¥
- Teleoperar **bra√ßo** com precis√£o milim√©trica

### Hardware

**3Dconnexion SpaceMouse Wireless**
- **Pre√ßo:** $150
- **Conex√£o:** USB wireless receiver
- **Precis√£o:** 0.01mm de resolu√ß√£o
- **Uso Profissional:** CAD, rob√≥tica, simula√ß√£o

### Integra√ß√£o ROS2

**Driver:** `spacenav_node` (ROS2)

```bash
# Instalar driver do kernel
sudo apt install spacenavd libspnav-dev

# Clonar pacote ROS2
cd ~/ros2_ws/src
git clone https://github.com/ros-drivers/joystick_drivers.git -b ros2
cd ~/ros2_ws
colcon build --packages-select spacenav

# Iniciar daemon
sudo systemctl start spacenavd

# Lan√ßar n√≥ ROS2
ros2 run spacenav spacenav_node
```

**T√≥pico publicado:**
```
/spacenav/twist  (geometry_msgs/Twist)
  - linear.x/y/z: transla√ß√£o
  - angular.x/y/z: rota√ß√£o
```

**Exemplo de Uso: Controlar Efetor Final (M√£o)**

```python
import rclpy
from geometry_msgs.msg import Twist, Pose
from moveit_msgs.srv import GetPositionIK

class SpaceMouseTeleop(Node):
    def __init__(self):
        super().__init__('spacemouse_teleop')

        # Subscribe to SpaceMouse
        self.sub = self.create_subscription(
            Twist, '/spacenav/twist', self.spacemouse_callback, 10
        )

        # Publicar pose do efetor final
        self.ee_pose_pub = self.create_publisher(
            Pose, '/target_end_effector_pose', 10
        )

        # Pose atual (inicializar em posi√ß√£o neutra)
        self.current_pose = Pose()
        self.current_pose.position.x = 0.5  # 50cm √† frente
        self.current_pose.position.z = 1.0  # 1m de altura

    def spacemouse_callback(self, msg):
        # Fator de escala (ajustar conforme necess√°rio)
        scale_translation = 0.001  # 1mm por unidade
        scale_rotation = 0.01      # 0.01 rad por unidade

        # Atualizar posi√ß√£o
        self.current_pose.position.x += msg.linear.x * scale_translation
        self.current_pose.position.y += msg.linear.y * scale_translation
        self.current_pose.position.z += msg.linear.z * scale_translation

        # Atualizar orienta√ß√£o (usando quaternion - simplificado)
        # (Em produ√ß√£o, usar biblioteca de transforma√ß√£o como tf2)

        # Publicar nova pose
        self.ee_pose_pub.publish(self.current_pose)
        self.get_logger().info(f'EE Position: x={self.current_pose.position.x:.3f}')
```

---

## üì± Tablet Touchscreen

### Vantagens da Interface Mobile

- ‚úÖ **Mobilidade** (acompanhar rob√¥ andando)
- ‚úÖ **Interface visual rica** (bot√µes grandes, gr√°ficos)
- ‚úÖ **Multitouch** (zoom, pan em mapas)
- ‚úÖ **C√¢meras integradas** (AR - Realidade Aumentada)

### Op√ß√µes de Software

<Tabs>
<TabItem value="webviz" label="üåê Webviz (Navegador Web)">

**Descri√ß√£o:** Interface web para ROS2 (similar ao rviz, mas no navegador)

**Vantagens:**
- ‚úÖ Funciona em qualquer tablet (iPad, Android, Surface)
- ‚úÖ Sem instala√ß√£o (apenas acessar URL)
- ‚úÖ Customiz√°vel (HTML/CSS/JS)

**Setup:**

```bash
# Instalar Foxglove Studio (substituto do Webviz)
# Acesse: https://foxglove.dev/download
# Ou use vers√£o web: https://studio.foxglove.dev/

# Lan√ßar ponte ROS2 ‚Üí WebSocket
sudo apt install ros-humble-rosbridge-suite
ros2 launch rosbridge_server rosbridge_websocket_launch.xml
```

**No tablet:**
1. Abrir navegador
2. Ir para `https://studio.foxglove.dev/`
3. Conectar em `ws://IP_DO_ROBOT:9090`
4. Adicionar pain√©is: C√¢mera, Telemetria, Mapa, Joystick Virtual

</TabItem>
<TabItem value="custom-app" label="üì± App Customizado">

**React Native + ROS2 (via rosbridge)**

```javascript
// Exemplo: Bot√£o de "Sentar"
import React from 'react';
import { Button } from 'react-native';
import ROSLIB from 'roslib';

const RobotControlApp = () => {
  const ros = new ROSLIB.Ros({
    url: 'ws://192.168.1.100:9090'  // IP do rob√¥
  });

  const sendSitCommand = () => {
    const cmdTopic = new ROSLIB.Topic({
      ros: ros,
      name: '/robot_commands',
      messageType: 'std_msgs/String'
    });

    const message = new ROSLIB.Message({
      data: 'sit'
    });

    cmdTopic.publish(message);
  };

  return (
    <Button title="ü™ë Sentar" onPress={sendSitCommand} />
  );
};
```

**Deploy:**
- iOS: Precisa Apple Developer Account ($99/ano)
- Android: Gr√°tis (Google Play ou sideload APK)

</TabItem>
<TabItem value="commercial" label="üíº Solu√ß√µes Comerciais">

**Unitree Official App (para H1/G1)**
- **Plataforma:** iOS/Android
- **Pre√ßo:** Gr√°tis (inclu√≠do com rob√¥)
- **Recursos:**
  - Joystick virtual
  - Visualiza√ß√£o de c√¢meras
  - Logs de erro
  - Modos pr√©-programados (andar, dan√ßar, carregar)

**ROS Mobile (Generic)**
- **GitHub:** [https://github.com/ROS-Mobile](https://github.com/ROS-Mobile)
- **Pre√ßo:** Open source
- **Recursos:**
  - Visualizar t√≥picos
  - Publicar mensagens simples
  - Mapa de navega√ß√£o (Nav2)

</TabItem>
</Tabs>

---

## ü•Ω Realidade Virtual (VR)

### Por Que VR para Teleopera√ß√£o?

**Vantagens:**
- ‚úÖ **Imers√£o total** (ver pelo "olhos" do rob√¥)
- ‚úÖ **Controle intuitivo** (mover seus bra√ßos = mover bra√ßos do rob√¥)
- ‚úÖ **Percep√ß√£o de profundidade** (crucial para manipula√ß√£o)
- ‚úÖ **Treinamento seguro** (simular cen√°rios perigosos)

**Desvantagens:**
- ‚ùå Lat√™ncia (30-50ms causa enjoo)
- ‚ùå Fadiga (uso cont√≠nuo &gt; 1h √© cansativo)
- ‚ùå Custo (headset + workstation potente)

### Hardware VR para Rob√≥tica

| Headset | Pre√ßo | Tracking | Lat√™ncia | Uso Recomendado |
|---------|-------|----------|----------|-----------------|
| **Meta Quest 3** | $500 | Inside-out (c√¢meras) | ~35ms | Simula√ß√£o, demos |
| **Valve Index** | $1000 | External (base stations) | ~25ms | Teleopera√ß√£o precisa |
| **HTC Vive Pro 2** | $1400 | External (SteamVR 2.0) | ~20ms | Profissional |
| **Varjo XR-4** | $4000 | Mixed Reality (alta res) | ~15ms | Industrial (NASA, BMW) |

### Stack de Software

<Tabs>
<TabItem value="unity-ros" label="üéÆ Unity + ROS#">

**Descri√ß√£o:** Renderizar c√¢meras do rob√¥ em VR usando Unity

**Arquitetura:**
```
Robot (ROS2) ‚Üí ROS# Bridge ‚Üí Unity (VR) ‚Üí Meta Quest 3
```

**Passos:**

1. **Instalar Unity 2022 LTS**
   - Download: [https://unity.com/](https://unity.com/)

2. **Instalar ROS# Package**
   ```bash
   # No computador do rob√¥
   sudo apt install ros-humble-rosbridge-suite
   ros2 launch rosbridge_server rosbridge_websocket_launch.xml
   ```

3. **Configurar Unity:**
   - Asset Store ‚Üí ROS TCP Connector
   - Criar objeto `ROS Connection` com IP do rob√¥

4. **Subscriber de C√¢mera:**
   ```csharp
   // Script C# no Unity
   using RosSharp.RosBridgeClient;
   using UnityEngine;

   public class RobotCameraVR : MonoBehaviour
   {
       RosSocket rosSocket;
       string topic = "/robot/camera/image_raw";

       void Start()
       {
           rosSocket = new RosSocket("ws://192.168.1.100:9090");
           rosSocket.Subscribe<sensor_msgs.Image>(topic, UpdateTexture);
       }

       void UpdateTexture(sensor_msgs.Image imageMsg)
       {
           // Converter ROS Image ‚Üí Unity Texture2D
           // Aplicar em um Quad na frente da c√¢mera VR
       }
   }
   ```

</TabItem>
<TabItem value="gazebo-vr" label="üèóÔ∏è Gazebo + VR Plugin">

**Descri√ß√£o:** Visualizar simula√ß√£o Gazebo em VR

**Plugin:** `gazebo_vr`

```bash
# Instalar
cd ~/gazebo_ws/src
git clone https://github.com/osrf/gazebo_vr.git
cd ~/gazebo_ws
colcon build

# Lan√ßar Gazebo com VR
export GAZEBO_PLUGIN_PATH=~/gazebo_ws/install/lib:$GAZEBO_PLUGIN_PATH
gazebo --verbose -s libgazebo_vr.so
```

**Controles:**
- Headset = C√¢mera
- Controladores = Teleopera√ß√£o de bra√ßos (se configurado)

</TabItem>
<TabItem value="isaac-vr" label="üé• Isaac Sim + VR">

**Descri√ß√£o:** NVIDIA Isaac Sim tem suporte nativo para VR

**Setup:**

1. **Lan√ßar Isaac Sim:**
   ```bash
   ~/.local/share/ov/pkg/isaac_sim-*/isaac-sim.sh
   ```

2. **Ativar VR:**
   - Window ‚Üí Extensions
   - Buscar "VR"
   - Ativar "omni.kit.vr"

3. **Conectar Headset:**
   - Suporta SteamVR (Valve Index, HTC Vive)
   - Window ‚Üí VR ‚Üí Start VR Session

**Recursos:**
- ‚úÖ Ray tracing em VR (gr√°ficos ultra-realistas)
- ‚úÖ Controlar rob√¥ com controladores VR
- ‚úÖ Physics interaction (pegar objetos virtuais)

</TabItem>
</Tabs>

---

## üé§ Comandos de Voz

### Quando Usar

- ‚úÖ Comandos de alto n√≠vel ("v√° para a cozinha")
- ‚úÖ M√£os ocupadas (operador carregando equipamento)
- ‚úÖ Acessibilidade (pessoas com mobilidade reduzida)
- ‚ùå Ambientes ruidosos (f√°brica com &gt; 80 dB)
- ‚ùå Comandos de precis√£o (dif√≠cil dizer "mova 5.3cm")

### Stack de Reconhecimento de Voz

<Tabs>
<TabItem value="google-cloud" label="‚òÅÔ∏è Google Cloud Speech-to-Text">

**Pr√≥s:** Alta precis√£o, multi-idioma
**Contras:** Pago ($0.006 por 15s), precisa internet

```python
import rclpy
from google.cloud import speech_v1
from std_msgs.msg import String

class VoiceCommands(Node):
    def __init__(self):
        super().__init__('voice_commands')
        self.client = speech_v1.SpeechClient()
        self.cmd_pub = self.create_publisher(String, '/voice_commands', 10)

    def listen(self):
        config = speech_v1.RecognitionConfig(
            encoding=speech_v1.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code='pt-BR',  # Portugu√™s Brasil
        )

        # Streaming audio (microfone)
        streaming_config = speech_v1.StreamingRecognitionConfig(config=config)

        # Processar resposta
        for response in responses:
            for result in response.results:
                transcript = result.alternatives[0].transcript
                self.process_command(transcript)

    def process_command(self, text):
        text = text.lower()

        if 'sentar' in text:
            cmd = String()
            cmd.data = 'sit'
            self.cmd_pub.publish(cmd)
        elif 'levantar' in text or 'ficar em p√©' in text:
            cmd = String()
            cmd.data = 'stand'
            self.cmd_pub.publish(cmd)
        elif 'parar' in text or 'pare' in text:
            cmd = String()
            cmd.data = 'emergency_stop'
            self.cmd_pub.publish(cmd)
        # Adicionar mais comandos...
```

</TabItem>
<TabItem value="whisper" label="ü§ñ Whisper (OpenAI) - Local">

**Pr√≥s:** Gr√°tis, roda local, c√≥digo aberto
**Contras:** Precisa GPU NVIDIA (modelo grande)

```bash
# Instalar Whisper
pip3 install openai-whisper

# Download modelo (escolher tamanho)
# tiny: 39M params, r√°pido mas menos preciso
# base: 74M params
# small: 244M params
# medium: 769M params (recomendado)
# large: 1550M params (melhor, mas lento)
```

```python
import whisper
import pyaudio

model = whisper.load_model("medium")  # Roda em RTX 3060

# Capturar 3 segundos de √°udio
def record_audio():
    # C√≥digo de grava√ß√£o...
    return audio_data

# Transcrever
result = model.transcribe(audio_data, language='pt')
print(result["text"])  # "Rob√¥, v√° para a cozinha"
```

</TabItem>
<TabItem value="vosk" label="üó£Ô∏è Vosk - Offline e Leve">

**Pr√≥s:** Roda em Raspberry Pi, totalmente offline
**Contras:** Menor precis√£o que Whisper/Google

```bash
pip3 install vosk
# Download modelo portugu√™s
wget https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip
unzip vosk-model-small-pt-0.3.zip
```

```python
from vosk import Model, KaldiRecognizer
import pyaudio

model = Model("vosk-model-small-pt-0.3")
recognizer = KaldiRecognizer(model, 16000)

mic = pyaudio.PyAudio()
stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)
stream.start_stream()

while True:
    data = stream.read(4000)
    if recognizer.AcceptWaveform(data):
        result = recognizer.Result()
        # {"text": "sentar"}
        print(result)
```

</TabItem>
</Tabs>

### Lista de Comandos de Voz Recomendados

```yaml
# Comandos seguros para voz (inequ√≠vocos)
comandos:
  movimentacao:
    - "andar para frente"
    - "andar para tr√°s"
    - "girar para esquerda"
    - "girar para direita"
    - "parar"  # SEMPRE deve funcionar!

  posturas:
    - "sentar"
    - "levantar"
    - "agachar"
    - "posi√ß√£o neutra"

  emergencia:
    - "parada de emerg√™ncia"
    - "desligar motores"

  tarefas:
    - "ir para cozinha"  # Requer Nav2 com mapa
    - "pegar caixa"      # Requer detec√ß√£o de objetos
    - "seguir pessoa"    # Requer tracking visual

# ‚ùå EVITAR comandos amb√≠guos:
  - "mais r√°pido" (quanto mais? 10%? 50%?)
  - "mover bra√ßo direito" (para onde? quanto?)
  - "um pouco para esquerda" (impreciso)
```

---

## üéØ Compara√ß√£o Pr√°tica: Qual Interface Usar?

### Cen√°rio 1: Desenvolvimento de Software (Simula√ß√£o)

**Escolha:** Teclado + Mouse
- R√°pido para testar comandos
- N√£o precisa hardware extra
- F√°cil debug (logs no terminal)

### Cen√°rio 2: Opera√ß√£o em F√°brica (Produ√ß√£o)

**Escolha:** Tablet + Comandos de Voz
- Operador pode andar pela linha de produ√ß√£o
- Voz para comandos r√°pidos ("parar", "retomar")
- Tablet para visualizar status

### Cen√°rio 3: Teleopera√ß√£o Complexa (Resgate, Demoli√ß√£o)

**Escolha:** VR + Joystick Profissional (HOTAS)
- VR para imers√£o e percep√ß√£o espacial
- Joystick para controle preciso de movimento
- Feedback h√°ptico (sentir resist√™ncia ao pegar objeto)

### Cen√°rio 4: Pesquisa Acad√™mica (Motion Capture)

**Escolha:** Motion Capture (Vicon, OptiTrack)
- Imitar movimentos humanos com alta precis√£o
- Coletar dados para machine learning
- Custo alto, mas necess√°rio para certos estudos

---

## üõ†Ô∏è Projeto Pr√°tico: Implementar Multi-Interface

**Objetivo:** Criar sistema que aceita comandos de **teclado, joystick E voz** simultaneamente.

**Arquitetura:**
```
[Teclado] ‚îÄ‚îê
           ‚îú‚îÄ‚Üí [Arbitrator Node] ‚îÄ‚Üí [Robot Controller]
[Joystick]‚îÄ‚î§      (prioridade)
           ‚îÇ
[Voz] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**L√≥gica de Prioridade:**
1. **E-Stop (voz ou bot√£o):** SEMPRE tem prioridade m√°xima
2. **Joystick:** Prioridade alta (controle fino)
3. **Voz:** Prioridade m√©dia (comandos de alto n√≠vel)
4. **Teclado:** Prioridade baixa (backup)

**C√≥digo Arbitrator:**

```python
class CommandArbitrator(Node):
    def __init__(self):
        super().__init__('command_arbitrator')

        # Subscribers
        self.sub_kbd = self.create_subscription(Twist, '/cmd_kbd', self.kbd_cb, 10)
        self.sub_joy = self.create_subscription(Twist, '/cmd_joy', self.joy_cb, 10)
        self.sub_voice = self.create_subscription(String, '/cmd_voice', self.voice_cb, 10)

        # Publisher final
        self.pub = self.create_publisher(Twist, '/cmd_vel', 10)

        # Estado
        self.last_command_source = None
        self.last_command_time = self.get_clock().now()

    def joy_cb(self, msg):
        # Joystick sempre sobrescreve outros
        self.publish_command(msg, 'joystick')

    def voice_cb(self, msg):
        # Voz s√≥ funciona se joystick n√£o foi usado nos √∫ltimos 2s
        elapsed = (self.get_clock().now() - self.last_command_time).nanoseconds / 1e9
        if self.last_command_source != 'joystick' or elapsed > 2.0:
            # Converter comando de voz em Twist
            cmd = self.voice_to_twist(msg.data)
            self.publish_command(cmd, 'voice')

    def publish_command(self, msg, source):
        self.pub.publish(msg)
        self.last_command_source = source
        self.last_command_time = self.get_clock().now()
        self.get_logger().info(f'Command from {source}')
```

---

## üìö Recursos e Ferramentas

### Pacotes ROS2 Essenciais

```bash
sudo apt install ros-humble-joy
sudo apt install ros-humble-teleop-twist-joy
sudo apt install ros-humble-teleop-twist-keyboard
sudo apt install ros-humble-rosbridge-suite  # Para web/mobile
```

### Tutoriais Recomendados

- **[ROS2 Joy Teleop Tutorial](https://index.ros.org/p/teleop_twist_joy/)**
- **[Foxglove Studio Docs](https://foxglove.dev/docs)**
- **[Unity VR + ROS](https://github.com/Unity-Technologies/ROS-TCP-Connector)**

---

## üîó Pr√≥ximos Passos

:::tip Pr√≥ximo M√≥dulo
**[üìä Telemetria e Monitoramento ‚Üí](./telemetria)**

Aprenda a monitorar o status do rob√¥ em tempo real: temperatura, bateria, erros e logs.
:::
